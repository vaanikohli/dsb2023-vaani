---
title: "E628 Pre-course assignment"
author: "YOUR NAME HERE"
date: 2023-05-08
format: 
  html:
    toc: true
    toc_float: true
    code-fold: true
editor: visual
---

```{r}
#| label: load-libraries
#| echo: false # This option disables the printing of code (only output is displayed).
#| message: false
#| warning: false

library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(janitor)
```

The goal is to test your software installation, to demonstrate competency in Markdown, and in the basics of `ggplot`.

# Install R and RStudio

You should successfully install R and R studio in your computer. We will do all of our work in this class with the open source (and free!) programming language [R](https://cran.r-project.org/). However, we will use [RStudio](https://www.rstudio.com/) as the main program to access R.

You can find details on how to [install both R and R studio here](https://dsb2023.netlify.app/reference/01-reference/)

## Install `tidyverse` and `janitor` packages

A clean installation of R is known as **base R**. We need to install a collection of packages named `tidyverse`. Go to the packages panel in the bottom right of RStudio, click on "Install," type `tidyverse`,`janitor` and press enter. You'll see a bunch of output in the RStudio console as all the packages are installed and, depending on the speed of your computer, this may take a while. You can also just paste and run the following

-   `install.packages("tidyverse")`
-   `install.packages("janitor")`

in the `console` (bottom left in RStudio) instead of using the packages panel.

You can find details on [installing the tidyverse here](https://dsb2023.netlify.app/reference/02-reference)

## Practice using Markdown

Assignments will be submitted using `Markdown` is a lightweight text formatting language that easily converts between file formats. It is integrated directly into [Quarto Markdown](https://quarto.org/docs/get-started/hello/rstudio.html), which combines R code, output, and written text into a single document (`.qmd`). You can [find more about markdown here](https://dsb2023.netlify.app/reference/03-reference/).

Quarto allows you to use a `Visual` editor, much like using word-processing software, but you can always switch back to `Source`.

## Pandoc

[Pandoc](http://pandoc.org)is a program that converts Markdown files into basically anything else. It was created by [John MacFarlane](https://johnmacfarlane.net), a philosophy professor at the University of California, Berkeley and is widely used as a writing tool and as a basis for publishing workflow. Kieran Healy's [Plain Text Social Science workflow](http://plain-text.co) describes how to use Markdown and then convert your Markdown document to HTML, PDF, word, etc.

You should change the file name from `your-name-pre-course.qmd` to your own name; if I were submitting, my file would be called `Kostis_Christodoulou.qmd`

# Task 1: Short bio written using markdown

You should write within this `qmd` file a brief biography of yourself using markdown syntax. I know you have already achieved a lot, but a couple of paragraphs is more than enough.

To achieve full marks, you should include at least 4 of the following elements:

-   Headers
-   Emphasis (italics or bold)
-   Lists
-   Links
-   Embedding images

> Please delete all the intro text I wrote and start writing your short biography after this blockquote.

# Task 2: Create a Github account

We will be using Github through the course, so please make sure you [register for a Github account](https://happygitwithr.com/github-acct.html). You can even add your github username in your short bio!

# Task 3: Animal rescue incidents attended by the London Fire Brigade

[The London Fire Brigade](https://data.london.gov.uk/dataset/animal-rescue-incidents-attended-by-lfb) attends a range of non-fire incidents (which we call 'special services'). These 'special services' include assistance to animals that may be trapped or in distress. The data is provided from January 2009 and is updated monthly. A range of information is supplied for each incident including some location information (postcode, borough, ward), as well as the data/time of the incidents. We do not routinely record data about animal deaths or injuries.

Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.

```{r}
#| label: load_animal_rescue_data
#| message: false
#| warning: false

url <- "https://data.london.gov.uk/download/animal-rescue-incidents-attended-by-lfb/01007433-55c2-4b8a-b799-626d9e3bc284/Animal%20Rescue%20incidents%20attended%20by%20LFB%20from%20Jan%202009.csv"

animal_rescue <- read_csv(url,
                          locale = locale(encoding = "CP1252")) %>% 
  
  #use janitor::clean_names() to clean names
  janitor::clean_names()

# quick look at the dataframe- how many rows- columns, type of variables (characters, numbers, etc )
glimpse(animal_rescue)
```

One of the more useful things one can do with any data set is quick counts, namely to see how many observations fall within one category. For instance, if we wanted to count the number of incidents by year, we would either use `group_by()... summarise()` or, simply [`count()`](https://dplyr.tidyverse.org/reference/count.html)

```{r}
#| label: instances_by_calendar_year
#| message: false
#| warning: false

animal_rescue %>% 
  dplyr::group_by(cal_year) %>% 
  summarise(count=n())

animal_rescue %>% 
  count(cal_year, name="count")

```

Once we `count()` how many incidents we have per year, we can pipe `%>%` the table to a ggplot and draw a simple time series chart.

```{r}
#| label: plot-by-calendar-year
#| message: false
#| warning: false
#| fig-cap: Incidents over time.

animal_rescue %>% 
  count(cal_year, name="count") %>% 
  
  # we dont have all the data for 2023, so let us filter it out
  filter(cal_year < 2023) %>% 
  
  # the result of count() is a dataframe, so we pass it to 
  ggplot() + 
  
  # map year (cal_year) on the x-axis, count on the y-axis
  aes( x = cal_year,
       y = count)+
  
  # we just want a time-series, line graph
  geom_line()+
  
  # also add the points to make graph easier to read
  geom_point()+
  
  # make sure y-axis starts at zero
  expand_limits(y = 0)+
  
  # add labels
  labs(
    title = "Animal rescue incidents have almost doubled post Covid-19",
    subtitle = "Animal rescue incidents attended by the LBF",
    x = NULL,
    y = NULL,
    caption = "Source: https://data.london.gov.uk/dataset/animal-rescue-incidents-attended-by-lfb") +
  
  theme_minimal() + 
  
  # change the theme, so title is left-aligned
  theme(plot.title.position = "plot") +
  
  # add one final layer of NULL, so if you comment out any lines
  # you never end up with a hanging `+` that awaits another ggplot layer
  NULL

```

Let us try to see how many incidents we have by animal group. Again, we can do this either using group_by() and summarise(), or by using count()

```{r}
#| label: animal_group_percentages
#| message: false
#| warning: false


animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  
  #group_by and summarise will produce a new column with the count in each animal group
  summarise(count = n()) %>% 
  
  # mutate adds a new column; here we calculate the percentage
  mutate(percent = round(100*count/sum(count),2)) %>% 
  
  # arrange() sorts the data by percent. Since the default sorting is min to max and we would like to see it sorted
  # in descending order (max to min), we use arrange(desc()) 
  arrange(desc(percent))


animal_rescue %>% 
  
  #count does the same thing as group_by and summarise
  # name = "count" will call the column with the counts "count" ( exciting, I know)
  # and 'sort=TRUE' will sort them from max to min
  count(animal_group_parent, name="count", sort=TRUE) %>% 
  mutate(percent = round(100*count/sum(count),2))


```

Do you see anything strange in these tables?

Finally, let us have a loot at the notional cost for rescuing each of these animals. As the LFB says,

> Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.

There is two things we will do:

1.  Calculate the mean and median `incident_notional_cost_a` for each `animal_group_parent`
2.  Plot a boxplot to get a feel for the distribution of `incident_notional_cost_a` by `animal_group_parent`.

Before we go on, however, we need to fix `incident_notional_cost_a` as it is stored as a `chr`, or character, rather than a number.

```{r}
#| label: parse_incident_cost
#| message: false
#| warning: false


# what type is variable incident_notional_cost from dataframe `animal_rescue`
typeof(animal_rescue$incident_notional_cost_a)

# readr::parse_number() will convert any numerical values stored as characters into numbers
animal_rescue <- animal_rescue %>% 

  # we use mutate() to use the parse_number() function and overwrite the same variable
  mutate(incident_notional_cost_a = parse_number(incident_notional_cost_a))

# incident_notional_cost from dataframe `animal_rescue` is now 'double' or numeric
typeof(animal_rescue$incident_notional_cost_a)

```

Now that `incident_notional_cost_a` is numeric, let us quickly calculate summary statistics for each animal group.

```{r}
#| label: stats_on_incident_cost
#| message: false
#| warning: false

animal_rescue %>% 
  
  # group by animal_group_parent
  group_by(animal_group_parent) %>% 
  
  # filter resulting data, so each group has at least 6 observations
  filter(n()>6) %>% 
  
  # summarise() will collapse all values into 3 values: the mean, median, and count  
  # we use na.rm=TRUE to make sure we remove any NAs, or cases where we do not have the incident cos
  summarise(mean_incident_cost = mean (incident_notional_cost_a, na.rm=TRUE),
            median_incident_cost = median (incident_notional_cost_a, na.rm=TRUE),
            sd_incident_cost = sd (incident_notional_cost_a, na.rm=TRUE),
            min_incident_cost = min (incident_notional_cost_a, na.rm=TRUE),
            max_incident_cost = max (incident_notional_cost_a, na.rm=TRUE),
            count = n()) %>% 
  
  # sort the resulting data in descending order. You choose whether to sort by count or mean cost.
  arrange(desc(count))

```

Compare the mean and the median for each animal group. What do you think this is telling us? Anything else that stands out? Any outliers?

Finally, let us plot a few plots that show the distribution of incident_cost for each animal group.

```{r}
#| label: plots_on_incident_costs_by_animal_group
#| message: false
#| warning: false

# base_plot
base_plot <- animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  filter(n()>6) %>% 
  ggplot(aes(x=incident_notional_cost_a))+
  facet_wrap(~animal_group_parent, scales = "free")+
  theme_bw()

base_plot + geom_histogram()
base_plot + geom_density()
base_plot + geom_boxplot()
base_plot + stat_ecdf(geom = "step", pad = FALSE) +
  scale_y_continuous(labels = scales::percent)



```

Which of these four graphs do you think best communicates the variability of the `incident_notional_cost_a` values? Also, can you please tell some sort of story (which animals are more expensive to rescue than others, the spread of values) and speculate about the differences in the patterns.

# Bonus Question: Total LFB Animal Rescue Cost over time

Using LFB's `incident_notional_cost_a`, plot a line graph showing the total incident notional cost between 2009 - 2022.

```{r}



```

# Submit the assignment

Render the completed Quarto Markdown file as an HTML document (use the "Render" button at the top of the script editor window) and email me your work.

## Details

If you want to, please answer the following

-   Who did you collaborate with: TYPE NAMES HERE
-   Approximately how much time did you spend on this problem set: ANSWER HERE
-   What, if anything, gave you the most trouble: ANSWER HERE
